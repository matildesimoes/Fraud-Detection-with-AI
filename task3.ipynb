{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tecnologias Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois das etapas de modelação e avaliação do modelo, foi feito este ficheiro com o objetivo de correr o código necessário para a submissão no **kaggle**. Foi agregado o código para preparar o treino e criadas as colunas que existiam no treino e que não foram criadas para o teste (**device_os_Linux** e **age_category_Senior**), pois tanto o dispositivo **Linux** como a idade **Senior** não existiam no teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('CreditCardTransactions/cities.csv')\n",
    "customers = pd.read_csv('CreditCardTransactions/customers.csv')\n",
    "merchants = pd.read_csv('CreditCardTransactions/merchants.csv')\n",
    "transactions = pd.read_csv('CreditCardTransactions/test_transactions.csv')\n",
    "\n",
    "customers_cities = pd.merge(customers, cities, on='city', how='left')\n",
    "transactions_customers = pd.merge(transactions, customers_cities, on='cc_num', how='left')\n",
    "final_data = pd.merge(transactions_customers, merchants, on='merchant', how='left')\n",
    "\n",
    "final_data.to_csv('CreditCardTransactions/merged_teste_dataset.csv', index=False)\n",
    "\n",
    "data = pd.read_csv('CreditCardTransactions/merged_teste_dataset.csv')\n",
    "imputed_data = pd.read_csv('CreditCardTransactions/imputed_data.csv')\n",
    "training_inputs = pd.read_csv('CreditCardTransactions/training_dataset.csv')\n",
    "training_classes = pd.read_csv('CreditCardTransactions/training_classes.csv')\n",
    "unscaled_data = pd.read_csv('CreditCardTransactions/unscaled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dob'] = pd.to_datetime(data['dob'])\n",
    "def categorize_age(dob):\n",
    "    today = datetime.today()\n",
    "    age = today.year - dob.year - ((today.month, today.day) < (dob.month, dob.day))\n",
    "    if 17 <= age <= 36:\n",
    "        return 'Young Adult'\n",
    "    elif 37 <= age <= 55:\n",
    "        return 'Adult'\n",
    "    elif 56 <= age <= 74:\n",
    "        return 'Middle Age'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "data['age_category'] = data['dob'].apply(categorize_age)\n",
    "data.drop(columns=['dob'], inplace=True)\n",
    "\n",
    "data = data.sort_values(by=['unix_time'])\n",
    "data['transactions_count'] = (\n",
    "    data.groupby(['cc_num', 'merchant'])['unix_time']\n",
    "      .cumcount() \n",
    ")\n",
    "data['transactions_count'] = data['transactions_count'] + 1\n",
    "\n",
    "unique_merchants = set()\n",
    "unique_merchants_count = []\n",
    "for merchant in data['merchant']:\n",
    "    unique_merchants.add(merchant) \n",
    "    unique_merchants_count.append(len(unique_merchants))\n",
    "data['unique_merchants_count'] = unique_merchants_count\n",
    "data = data.drop(columns=['merchant'])\n",
    "\n",
    "data['datetime'] = pd.to_datetime(data['unix_time'], unit='s')\n",
    "data.sort_values(by=['cc_num', 'datetime'], inplace=True)\n",
    "data['time_since_last'] = data.groupby('cc_num')['datetime'].diff().dt.total_seconds()\n",
    "data['time_since_last'] = data['time_since_last'].fillna(0)\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "def categorize_period(hour):\n",
    "    if 0 <= hour < 8:\n",
    "        return 'Madrugada'\n",
    "    elif 8 <= hour < 13:\n",
    "        return 'Manhã'\n",
    "    elif 13 <= hour < 18:\n",
    "        return 'Tarde'\n",
    "    else:\n",
    "        return 'Noite'\n",
    "data['period_of_day'] = data['hour'].apply(categorize_period)\n",
    "data['day_of_week'] = data['datetime'].dt.day_name()\n",
    "day_mapping = {'Sunday': 0, 'Monday': 1, 'Tuesday': 2, 'Wednesday': 3,\n",
    "               'Thursday': 4, 'Friday': 5, 'Saturday': 6}\n",
    "data['day_of_week_num'] = data['day_of_week'].map(day_mapping)\n",
    "data['day_of_week_sin'] = np.sin(2 * np.pi * data['day_of_week_num'] / 7)\n",
    "data['day_of_week_cos'] = np.cos(2 * np.pi * data['day_of_week_num'] / 7)\n",
    "period_mapping = {'Madrugada': 0, 'Manhã': 1, 'Tarde': 2, 'Noite': 3}\n",
    "data['period_of_day_num'] = data['period_of_day'].map(period_mapping)\n",
    "data['period_of_day_sin'] = np.sin(2 * np.pi * data['period_of_day_num'] / 4)\n",
    "data['period_of_day_cos'] = np.cos(2 * np.pi * data['period_of_day_num'] / 4)\n",
    "data = data.drop(columns=['hour', 'day_of_week', 'day_of_week_num', \n",
    "                          'period_of_day', 'period_of_day_num', 'datetime', 'unix_time', 'cc_num'])\n",
    "\n",
    "indexes = data[['index']].copy()\n",
    "data = data.drop(columns= ['index', 'first', 'last', 'lat', 'long', 'merch_lat', 'merch_long', 'merchant_id', 'trans_date_trans_time', 'street', 'zip', 'state', 'city_pop', 'trans_num'])\n",
    "\n",
    "numeric_columns = unscaled_data.select_dtypes(include=['float64' , 'int64']).columns\n",
    "scaler = MinMaxScaler()\n",
    "unscaled_data[numeric_columns] = scaler.fit_transform(unscaled_data[numeric_columns])\n",
    "data[numeric_columns] = scaler.transform(data[numeric_columns])\n",
    "\n",
    "numerical_cols = imputed_data.select_dtypes(include=['number']).columns\n",
    "categorical_cols = imputed_data.select_dtypes(include=['object', 'category']).columns\n",
    "mean_values = imputed_data[numerical_cols].mean()\n",
    "mode_values = imputed_data[categorical_cols].mode().iloc[0]\n",
    "data[numerical_cols] = data[numerical_cols].fillna(mean_values)\n",
    "data[categorical_cols] = data[categorical_cols].fillna(mode_values)\n",
    "\n",
    "data['city_has_info'] = data['city'].apply(lambda x: 0 if x == 'Test City' else 1)\n",
    "\n",
    "categorical_columns1 = ['gender']\n",
    "data = pd.get_dummies(data, columns=categorical_columns1, drop_first=True, dtype=int)\n",
    "categorical_columns2 = ['device_os', 'category', 'age_category', 'job', 'city']\n",
    "data = pd.get_dummies(data, columns=categorical_columns2, drop_first=False, dtype=int)\n",
    "\n",
    "testing_inputs = data.copy()\n",
    "\n",
    "testing_inputs['device_os_Linux'] = 0\n",
    "colunas = testing_inputs.columns.tolist()\n",
    "colunas.insert(10, colunas.pop(colunas.index('device_os_Linux')))\n",
    "testing_inputs = testing_inputs[colunas]\n",
    "\n",
    "testing_inputs['age_category_Senior'] = 0\n",
    "colunas = testing_inputs.columns.tolist()\n",
    "colunas.insert(22, colunas.pop(colunas.index('age_category_Senior')))\n",
    "testing_inputs = testing_inputs[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('smote_tomek', SMOTETomek(random_state=42, sampling_strategy=0.4)),\n",
    "    ('decision_tree', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "sf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline, training_inputs, training_classes, cv=sf, scoring='roc_auc')\n",
    "pipeline.fit(training_inputs, training_classes)\n",
    "\n",
    "predictions = pipeline.predict(testing_inputs)\n",
    "probas = pipeline.predict_proba(testing_inputs)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': indexes['index'],\n",
    "    'is_fraud': probas  \n",
    "})\n",
    "\n",
    "submission.to_csv('tentativas/teste1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('smote_tomek', SMOTETomek(random_state=42, sampling_strategy=0.4)),\n",
    "    ('svm', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "sf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline, training_inputs, training_classes, cv=sf, scoring='roc_auc')\n",
    "pipeline.fit(training_inputs, training_classes)\n",
    "\n",
    "predictions = pipeline.predict(testing_inputs)\n",
    "probas = pipeline.predict_proba(testing_inputs)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': indexes['index'],\n",
    "    'is_fraud': probas  \n",
    "})\n",
    "\n",
    "submission.to_csv('tentativas/teste2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('smote_tomek', SMOTETomek(random_state=42, sampling_strategy=0.4)),\n",
    "    ('logistic_regression', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'logistic_regression__penalty': ['l1', 'l2'],\n",
    "    'logistic_regression__C': [0.1, 1.0],\n",
    "    'logistic_regression__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "sf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=sf,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(training_inputs, training_classes)\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "predictions = best_pipeline.predict(testing_inputs)\n",
    "probas = best_pipeline.predict_proba(testing_inputs)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': indexes['index'],\n",
    "    'is_fraud': probas  \n",
    "})\n",
    "\n",
    "submission.to_csv('tentativas/teste3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('smote_tomek', SMOTETomek(random_state=42, sampling_strategy=0.4)),\n",
    "    ('neural_network', MLPClassifier(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "sf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline, training_inputs, training_classes, cv=sf, scoring='roc_auc')\n",
    "pipeline.fit(training_inputs, training_classes)\n",
    "\n",
    "predictions = pipeline.predict(testing_inputs)\n",
    "probas = pipeline.predict_proba(testing_inputs)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': indexes['index'],\n",
    "    'is_fraud': probas  \n",
    "})\n",
    "\n",
    "submission.to_csv('tentativas/teste4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "random_forest_parameter_grid = {    \n",
    "    'model__max_features': ['log2', 'sqrt'],  \n",
    "    'model__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTETomek(random_state=42, sampling_strategy=0.4)),\n",
    "    ('model', random_forest)\n",
    "])\n",
    "\n",
    "sf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "random_forest_grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=random_forest_parameter_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=sf,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_forest_grid_search.fit(training_inputs, training_classes)\n",
    "best_pipeline = random_forest_grid_search.best_estimator_\n",
    "\n",
    "predictions = best_pipeline.predict(testing_inputs)\n",
    "probas = best_pipeline.predict_proba(testing_inputs)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': indexes['index'],\n",
    "    'is_fraud': probas  \n",
    "})\n",
    "\n",
    "submission.to_csv('tentativas/teste5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optei por executar todos os modelos que implementei na fase anterior diretamente no **Kaggle**, descartando os resultados obtidos localmente. Essa decisão mostrou-se acertada, uma vez que as pontuações obtidas localmente nem sempre correspondiam às obtidas no **Kaggle**.\n",
    "\n",
    "Abaixo, encontra-se uma tabela que expõe o nome do teste, o modelo utilizado e a pontuação obtida no **Kaggle**.\n",
    "O código para chegar a estes resultados está nos blocos de código acima.\n",
    "\n",
    "| Nome do Teste | Modelo Utilizado | Valor Obtido |\n",
    "|---------------|------------------|--------------|\n",
    "| teste1.csv    |  Árvore de Decisão Sem GridSearch      | 0.50345|\n",
    "| teste2.csv    | SVM Sem GridSearch | 0.54154      | \n",
    "| teste3.csv    | Logistic Regression Com GridSearch | 0.48420      |\n",
    "| teste4.csv    | Neural Network Sem GridSearch| 0.63801      |\n",
    "| teste5.csv    | Random Forest Com GridSearch | 0.59903  | "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
