{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tecnologias Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de analisar e tratar todos os dados, vamos passar para as etapas de modelação e avaliação. Assim, é necessário voltar a ler os dados do **dataset** tratado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CreditCardTransactions/cities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelação\n",
    "\n",
    "Em primeiro lugar, desenvolvemos um modelo de classificação baseado numa **Árvore de Decisão**. Tendo em conta que a variável-alvo é categórica, pelo que este é um problema de classificação e o objetivo do modelo é classificar registos, tomando decisões a partir dos atributos de cada cliente, este algoritmo considera-se adequado para o efeito.\n",
    "\n",
    "Em segundo lugar, implementamos uma **Rede Neuronal**, que é um modelo de *deep learning* com capacidade para aprender a partir dos dados, sendo capaz de identificar padrões complexos e de fazer previsões precisas.\n",
    "\n",
    "Em terceiro lugar, criamos um modelo com base em ***K-Nearest Neighbors*** (K-NN). Este é um algoritmo que classifica novos dados através da sua proximidade em relação aos dados já existentes, tendo em consideração as classes dos *k* vizinhos mais próximos.\n",
    "\n",
    "Para além disto, construímos um modelo de classificação assente numa ***Support Vector Machine*** (SVM). Esta abordagem tenta encontrar o hiperplano que melhor separa os registos das diferentes classes, maximizando a margem entre esse hiperplano e os registos das duas classes.\n",
    "\n",
    "Por último, apresentamos um ***Random Forest Classifier***, que, sendo um modelo de *ensembling*, combina várias árvores de decisão para classificar melhor os dados.\n",
    "\n",
    "Os modelos devem ser treinados com um conjunto de dados de treino e testados com um conjunto de dados de teste. O conjunto de teste vai corresponder a 25% do *dataset*.\n",
    "\n",
    "Para a construção de alguns modelos, como a rede neuronal, o *k-nearest neighbors* e o *support vector machine*, é necessário normalizar os dados de maneira a que tenham média 0 e variância 1, aplicando este processo ao conjunto de treino e ao conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepared_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprepared_data\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_fraud\u001b[39m\u001b[38;5;124m'\u001b[39m], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m prepared_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_fraud\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m (training_inputs, testing_inputs, training_classes, testing_classes) \u001b[38;5;241m=\u001b[39m train_test_split(all_inputs, all_labels, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m13\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepared_data' is not defined"
     ]
    }
   ],
   "source": [
    "all_inputs = prepared_data.drop(['is_fraud'], axis = 1)\n",
    "\n",
    "all_labels = prepared_data['is_fraud']\n",
    "\n",
    "(training_inputs, testing_inputs, training_classes, testing_classes) = train_test_split(all_inputs, all_labels, test_size = 0.25, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "training_inputs_scaled = scaler.fit_transform(training_inputs)\n",
    "\n",
    "testing_inputs_scaled = scaler.transform(testing_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como foi visto anteriormente, o *dataset* é desequilibrado, com uma proporção de 1.9% de fraudes. \n",
    "\n",
    "Assim, em todos os casos, com exceção da rede neuronal, para melhorar os resultados obtidos no processo de afinação de parâmetros utilizando o *Grid Search* e para evitar flutuações dos resultados devido à divisão aleatória dos dados no conjunto de treino e teste, recorrer-se-á a *cross-validation*. Neste caso, considera-se *k* = 10 e realiza-se *stratified cross-validation*, de modo que a proporção da variável-alvo se mantenha constante em cada um dos subconjuntos gerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
